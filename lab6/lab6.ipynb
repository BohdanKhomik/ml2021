{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторна робота 6\n",
    "### Студента групи МІТ-31 (підгрупа 2)\n",
    "### Хоміка Богдана Сергійовича\n",
    "\n",
    "## Завдання\n",
    "1. Виконати вирішення задачs класифікації для 3 класів з набору даних food101\n",
    "2. Індекси класів визначити індивідуально за залежностями: i1=n-1,i2=n+29,i3=n+59 (де і1,і2,і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних, n - номер за списком (обчислені значення індексів вказані у даному документі у стовпчиках D:F) )\n",
    "3. Отримані результати викласти на github у репозиторій ml2021 в основну (default) гілку в папці Lab6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the downloaded file\n",
    "zip_ref = zipfile.ZipFile(\"101_food_classes_10_percent.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir=\"101_food_classes_10_percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(main_dir):\n",
    "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"101_food_classes_10_percent/train/\") # turn our training path into a Python path\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Індекси класів визначити індивідуально за залежностями: i1=n-1,i2=n+29,i3=n+59 \n",
    "# (де і1,і2,і3 - індекс класу (починаючи з 0) у відсортованому за алфавітом наборі даних,\n",
    "# n - номер за списком (обчислені значення індексів вказані у даному документі у стовпчиках D:F))\n",
    "\n",
    "n = 18\n",
    "\n",
    "l = []\n",
    "arr = (n - 1, n + 29, (n + 59) % 100)\n",
    "for i in range(len(class_names)):\n",
    "    if i in arr:\n",
    "        l.append(class_names[i])\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_dir, target_class):\n",
    "      # Setup target directory (we'll view images from here)\n",
    "  target_folder = target_dir+target_class\n",
    "\n",
    "  # Get a random image path\n",
    "  random_image = random.sample(os.listdir(target_folder), 1)\n",
    "\n",
    "  # Read in the image and plot it using matplotlib\n",
    "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "  plt.imshow(img)\n",
    "  plt.title(target_class)\n",
    "  plt.axis(\"off\");\n",
    "\n",
    "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
    "\n",
    "  return img\n",
    "\n",
    "  # View a random image from the training dataset\n",
    "img = view_random_image(target_dir=\"101_food_classes_10_percent/train2/\",\n",
    "                        target_class=\"apple_pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Setup the train and test directories\n",
    "train_dir = main_dir+\"/train2/\"\n",
    "test_dir = main_dir+\"/test2/\"\n",
    "\n",
    "# Import data from directories and turn it into batches\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size=32, # number of images to process at a time \n",
    "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
    "                                               class_mode=\"sparse\", # type of problem we're working on\n",
    "                                               seed=42)\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"sparse\",\n",
    "                                               seed=42)\n",
    "\n",
    "\n",
    "\n",
    "model_1 = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(filters=10, \n",
    "                         kernel_size=3, # can also be (3, 3)\n",
    "                         activation=\"relu\", \n",
    "                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
    "                            padding=\"valid\"), # padding can also be 'same'\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
    "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
    "  tf.keras.layers.MaxPool2D(2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "history_1 = model_1.fit(train_data,\n",
    "                        epochs=2,\n",
    "                        steps_per_epoch=len(train_data),\n",
    "                        validation_data=valid_data,\n",
    "                        validation_steps=len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history_1.history).plot(xlabel=\"epochs\", \n",
    "ylabel=\"loss\",title=\"History ins_model\", xlim=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "    \"\"\"\n",
    "    Returns separate loss curves for training and validation metrics.\n",
    "    \"\"\" \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(len(history.history['loss']))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(epochs, loss, label='training_loss')\n",
    "    plt.plot(epochs, val_loss, label='val_loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('model1.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
